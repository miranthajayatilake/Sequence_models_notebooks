{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence models \n",
    "\n",
    "## Week 1\n",
    "\n",
    "\n",
    "<img src=\"imgs/1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notations\n",
    "\n",
    "<img src=\"imgs/2.jpg\">\n",
    "\n",
    "\n",
    "#### Representing words\n",
    "\n",
    "TO represent words in a vocabulary (dictionary) on-hot encoding can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RNN (Recurrent Neural Networks)\n",
    "\n",
    "Activation is acarried to the following layers\n",
    "\n",
    "<img src=\"imgs/3.jpg\">\n",
    "\n",
    "<img src=\"imgs/4.jpg\">\n",
    "\n",
    "<img src=\"imgs/5.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/6.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now looking at where the input X and output Y are two different lengths and types\n",
    "\n",
    "Many-to-One\n",
    "\n",
    "<img src=\"imgs/7.jpg\">\n",
    "\n",
    "One to many and many to many\n",
    "\n",
    "<img src=\"imgs/8.jpg\">\n",
    "\n",
    "Summery\n",
    "\n",
    "<img src=\"imgs/9.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model\n",
    "\n",
    "gives the probability for a sequence of words that is likely correct\n",
    "\n",
    "First get a big dataset of words and make vocabulary\n",
    "Then tokenize (one-hot)\n",
    "\n",
    "The y(hat) is predicting what is the chance that the input word is follwed by another word from the dictionary. Uses softmax activation.\n",
    "So the first X<1> is a vectr of zero. And the output of the first layer is predicting what the first word can be and it is the the input of the sencond layer, predicting what can be the second word given the first word.\n",
    "\n",
    "<img src=\"imgs/10.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling novel sequences\n",
    "\n",
    "<img src=\"imgs/11.jpg\">\n",
    "\n",
    "- Charactor level RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanishing gradient problem in RNN\n",
    "\n",
    "Inreasing or decreasing derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gated Recurrent Unit (GRU)\n",
    "\n",
    "<img src=\"imgs/12.jpg\">\n",
    "<img src=\"imgs/13.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short Term Memory (LSTM)\n",
    "\n",
    "<img src=\"imgs/14.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN\n",
    "\n",
    "<img src=\"imgs/15.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep RNNs\n",
    "\n",
    "<img src=\"imgs/16.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
